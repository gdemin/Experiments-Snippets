---
title: "Experiments&Snippets"
author: "Gregory Demin"
output: html_document
---

### 2014-11-08 Стандартное отклонение распределения выборочных средних (ЦПТ)

По идее, оно должно быть SD_выборки/sqrt(N_выборки) и не меняться с количеством повторов эксперимента. Эксперимент - это случайная выборка из N_sample элементов. Соответственно, мы повторяем этот эксперимент разное количество раз. 

```{r}

set.seed(20140811)

N_sample = 30
N_exp = c(10,50,100,200,500,1000,5000, 50000)

res = lapply(N_exp, function(N){
    experiments = replicate(N,mean(rnorm(N_sample)))
    c(mean = mean(experiments),sd = sd(experiments),sd_exper = 1/sqrt(N_sample))
    
    })

do.call(rbind,res) # две последние колонки должны быть примерно равны

```

Да, действительно не зависит от количества повторов. Впрочем, это было очевидно уже при написании программы. 
Заодно проверим покрытие - будет ли выборочное среднее в 95% случаях лежать в интервале +/-1.96*SD_выборки/sqrt(N_выборки).

```{r}

N_sample = 30
N_exp = c(10,50,100,200,500,1000,5000, 50000)

res = lapply(N_exp, function(N){
    experiments = replicate(N,abs(mean(rnorm(N_sample))) < 1.96/sqrt(N_sample))
    mean(experiments)
    
    })

do.call(rbind,res) # Должно быть в районе 0.95

```

Да, покрытие примерно 95%.


### 2014-11-08 Эксперименты с %>% и dplyr - интересно проверить, как он будет вести с any и if

```{r}
library(dplyr)
df = data.frame(a=1:5,b=5:1)

any(df$a<6) # должно быть TRUE

df$a<6 %>% any() # так не работает

df$a<6 %>% any # так не работает 

# оказывается проблема в приоритете операций
(df$a<6) %>% any() # так работает, правильное TRUE
(df$a<6) %>% any # так работает, правильное TRUE

# тест if - шансов мало

# (df$a<6) %>% any() %>% if() df$d=0 else df$d=1 # оно и не работает...


```

А общая идея была, чтобы можно было писать проверку в виде цепочек. 
Типа: 
df %>% check(a,1:5) %>% corr(99)  # то есть, наверное и так можно сделать, надо только функции доработать

Сложный вопрос - надо как-то получать имена переменных в номральном виде, как select в dplyr. Наверное, этот select и надо использовать. Типа, сначала запускаешь выделенное до corr, получаешь список ошибок. Потом, если запускаешь с corr, то будет исправление.
Вместо corr, наверное все-таки clean - чтобы не путать с корреляциями.
По пути надо таскать с собой атрибуты - текущая проверка, текущие переменные для условий. Хотя, может и лучше зафиксировать их раз и навсегда. Сделать в пакете константы. Надо как-то еще переменную id передавать.

Самая засада - надо бы удобный просмотрщик ошибок. И, может быть, набор алгоритмов исправления...

### 2014-12-21 Эксперименты с SVD-декомпозицией, анализом главных компонент и ковариацией

```{r}
# создаем случайную матрицуу размером Nxp

N = 100
p = 10

set.seed(20141221)
dat = matrix(rnorm(N*p),nrow = N)

weight = runif(N)
# вычитаем  центры из каждой колонки - без этого ничего не будет

dat = scale(dat,center = TRUE, scale= FALSE)
stdev = apply(dat,2,sd) # вектор стандартных отклонений

all.equal(
    sqrt(sum((weight - mean(weight))^2)/(N-1)), # N-1 тоже под корнем!
    sd(weight)
    )

all.equal(
    sum((weight - mean(weight))^2)/(N-1), # стандартное отклонение - тупо корень из вариации
    var(weight)
    )

all.equal(
    cov(dat),
    var(dat)  # а вот функция для вариации почему-то определена совсем не так, как стандартное отклонение
    )

all.equal(
    diag(cov(dat)),
    (apply(dat,2,sd))^2 
    )

all.equal(
    t(dat) %*% dat/(N-1),
    cov(dat) # ковариация считается довольно просто
    )  # cov(X) = t(X) * X / (nrow(X) - 1)  # только для центрированных переменных

all.equal(
    t(dat) %*% dat/(N-1)/(stdev %*% t(stdev)),
    cor(dat) # для корреляции нормируем ковариацию на стандартное отклонение соответствующих переменных
)

# если использовать вес, то там совсем все сложно становится...
# unbias estimation в R по умолчанию
weight_norm = weight/sum(weight) # нормализуем вес
all.equal(
    t(dat) %*% (dat*weight_norm)/(1-sum(weight_norm^2)),
    cov.wt(dat,center=FALSE, wt = weight_norm,method="unbias")$cov
    ) # очень странный делитель. Непонятно зачем там квадраты весов...

# однако, если maximum-likelihood, то более понятно. 
all.equal(
    t(dat) %*% (dat*weight)/sum(weight),
    cov.wt(dat,center=FALSE, wt = weight,method="ML")$cov
    ) # Чтобы считало, как в SPSS, надо делить на (sum(weight)-1)??

```
Для центрированного набора данных X из N наблюдений

1. cov(X) = X' * X /(N-1)
2. cov(X,вес = wt) = X' * (Xw) /sum(w)  # для метода максимального правдоподобия
3. Корреляция - это ковариация, нормированная на стандартные отклонения соответствующих переменных

### допись 2015-02-11 по мотивам Trevor Hastie, Robert Tibshirani, Jerome Friedman, "Elements of statistical learning"

```{r}

u_d_v = svd(dat) # декомпозиция dat = u %*% d %*% t(v)
u = u_d_v$u
d = diag(u_d_v$d)
v = u_d_v$v

prc = prcomp(dat) # главные компоненты
comp = predict(prc,newdata=dat) # рассчитываем их значения
dimnames(comp) = NULL

all.equal(comp,u %*% d) # да, главные компоненты - это матричное умножение UD из SVD-декомпозиции 
x = prc$x
dimnames(x) = NULL
all.equal(x,u %*% d)

rotation = prc$rotation
dimnames(rotation) = NULL
all.equal(rotation,v) # V-компонента - матрица поворота

# соответсвенно, достаточно очевидно

all.equal(dat %*% v, comp ) # v - исходные переменные переводит в компоненты
all.equal(dat, comp %*% t(v),check.attributes = FALSE) # t(v) - переводит компоненты в исходные переменные

# TODO ортогональность



```



### 2015-02-11 correlation of r1 and r2 is x. Probability of r1 > r2?

Вопрос с crossvalidated: [correlation of r1 and r2 is x. Probability of r1 > r2?](http://stats.stackexchange.com/questions/137182/correlation-of-r1-and-r2-is-x-probability-of-r1-r2)

>Just a quick probability interview question.
>
>If the correlation of two variables r1, r2 is x. What's the probability that a sample of r1 is greater than a sample of r2?
>
>let me update the question. This is what the interviewer originally asked: the stock moves every day (r1 in my model) and you have a predictor (r2 in my model) that predicts the stock return with correlation of x. You make trades according to this predictor. What's the portion of your winning trades?


```{r}

# сначала проверим процент объясненной дисперсии

set.seed(20150211)
N = 1000 # количество точек

x = rnorm(N) # независимая переменная

eps = rnorm(N) # ошибка

y = x + eps  # у нас стандратное откклонение x равно 1, у ошибки тоже 1. Соотвсетвенно, стандартное отклонение y должно быть sqrt(2)

sqrt(2)

sd(y)

# или, еще более вычислительный эксперимент

vec_sd = replicate(10000,{sd(rnorm(N) + rnorm(N))})
plot(density(vec_sd))
abline(v=sqrt(2))
t.test(vec_sd,mu=sqrt(2)) # получается все-таки иногда нестыковочка

# зависимость y от x у нас объясняет половину дисперсии в y
# r^2 = 1/2, соответсвенно корреляция должна быть равна 1/sqrt(2)
cor(y,x)
1/(sqrt(2))

vec_cor = replicate(10000,{x = rnorm(N);cor(x,x + rnorm(N))})
plot(density(vec_cor))
abline(v=1/sqrt(2))
t.test(vec_cor,mu=1/sqrt(2)) # тоже немножечко похоже на правду

# Рассматриваем победу, как правильное указание направления движения
summary(lm(y ~ x)) # как и задумывалось, коэффициент равен 1

mean(sign(diff(y))==sign(diff(x))) # а вот и хрен - получается, что он очень отдаленно похож на коэффициент корреляции. Но не равен ему

prediction_vec=replicate(1000,{
    x = rnorm(N)
    y = x + rnorm(N)
    mean(sign(diff(y))==sign(diff(x))) # проще diff(y)*diff(x) > 0, но со знаками понятнее
    
})

summary(prediction_vec)
plot(density(prediction_vec))
abline(v=1/sqrt(2)) # даже очень далек от него
abline(v=0.75, col="blue") # а 0.75 похоже

# попробуем построить зависимость
# доля правильных предсказаний от стандартного отклонения ошибки

dep_list = lapply(seq(0,10,0.1),function(eps_sd) {rowMeans(replicate(1000,{
    x = rnorm(N)
    y = x + rnorm(N,mean = 0, sd = eps_sd)
    c(eps_sd, cor(x,y),
    mean(sign(diff(y))==sign(diff(x)))) 
    
}))})

dep_mat=as.data.frame(do.call(rbind,dep_list))
colnames(dep_mat) = c("Error SD","Correlation","Prediction accuracy")
plot(dep_mat[,2:3]) # тут непонятная зависимость, но на начальных этапах похожа на линейную
mod1 = lm(`Prediction accuracy` ~ Correlation, data = dep_mat,subset=Correlation<0.8)
abline(mod1,col="blue")
plot(dep_mat[,1:2]) # зависимость должна быть как sqrt(1/(1+eps_sd^2)), так как квадрат корреляции - это доля объясненной вариации
eps_sd = seq(0,10,0.1) 
lines(eps_sd,sqrt(1/(1+eps_sd^2)),col="blue") # тютелька в тютельку:) 

plot(dep_mat[,c(1,3)]) # в виде гипотезы 0.5+0.5/(1+eps_sd)
with(dep_mat,lines(`Error SD`,0.5+0.5/(1+(`Error SD`)^1.2),col="blue")) # еле-еле похоже... подогнал кривулькой с показателем степени 1.2 - очень странно

# нелинейную модель так и не удалось подогнать...
# colnames(dep_mat)[3] = "pred"
# nls_mat = data.frame(pred = dep_mat[,"Prediction accuracy"] + rnorm(nrow(dep_mat), sd = 0.01),Correlation = dep_mat[,"Correlation"])
# mod2 = nls(pred ~ base + a/(d+Correlation^alfa), data = nls_mat,start=c(base=0.5,a=0.5,d=1,alfa=1))
# а если линейную
mod3 = lm(`Prediction accuracy` ~ I(0.5+0.5/(1+(`Error SD`)^1.2)), data = dep_mat)
summary(mod3) # нереально хороший р-квадрат

```

А мораль всего этого такая - что простой ответ на этот простой вопрос я не нашел.

### 2015-02-11 DiagrammeR

Кириллицу мы не поддерживаем...:( Да и с масштабированием проблемы. И вообще странно работает.

```{r}

library(DiagrammeR)

DiagrammeR("
           graph TB;
           A{Life} -->B(Family);
           A --> C[Work];
           ")

```


### 2015-03-13 Заключенные и 100 ящиков

По условию задачи в тюрьме находится 100 заключенных, каждый из которых имеет личный номер от 1 до 100. Тюремщик решает дать заключенным шанс на освобождение и предлагает пройти придуманное им испытание. Если все заключенные справятся, то они свободны, если хотя бы один провалится — все умрут.

Тюремщик идет в секретную комнату и подготавливает 100 коробок с крышками. На каждую коробку он наносит числа с нумерацией от 1 до 100. Затем он приносит 100 бумажных табличек, по числу заключенных, и нумерует эти таблички от 1 до 100. После этого он перемешивает 100 табличек и помещает в каждую коробку по одной табличке, закрывая крышку. Заключенные не видят, как тюремщик выполняет все эти действия.
Соревнование начинается, тюремщик отводит каждого заключенного по одному в комнату с коробками и говорит заключенным, что они должны найти коробку, в которой будет находиться табличка с номером заключенного. Заключенные пытаются найти табличку со своим номером, открывая коробки. Каждому разрешается открыть до 50-ти коробок; если каждый из заключенных найдет свой номер, то заключенных отпустят, если хотя бы один из них не найдет свой номер за 50 попыток, то все заключенные умрут.
Для того, чтобы заключенные были освобождены, ВСЕ заключенные должны пройти испытание успешно.

Так какой же шанс, что заключенных помилуют?

* После открытия коробки заключенным и проверки им таблички она помещается обратно в коробку и крышка снова закрывается;
* Местами таблички менять нельзя;
* Заключенные не могут оставлять друг другу подсказки или как-то взаимодействовать друг с другом после начала испытания;
* Заключенным разрешается обсудить стратегию до начала испытания.


```{r}


# zk_count - количеcтво заключенных
# max_trial - количество попыток у одного заключенного

single_experiment = function(zk_count, max_trial){ 
    
    zk_num = seq_len(zk_count) # последовательно нумеруем заключенных   
    boxes = sample(zk_num) # помещаем и перемешиваем номера заключенных в коробках
    
    zk_success = 0 # количество заключенных, которые нашли свои номера за max_trial попыток
    
    for (zk in zk_num){ # перебираем заключенных
        box = zk # номер вскрываемого ящика 
        trial = 1 # номер попытки
        # в этом цикле каждый заключенный вскрывает ящики
        while (trial <=max_trial){
            if (boxes[box] == zk){
                # успех, он нашел свой номер
                zk_success = zk_success + 1
                break # дальше не пробуем
            } else {
                    box = boxes[box] # берем номер ящика, куда смотреть даальше    
            }
            trial = trial + 1
        }
    }
    zk_success # возвращаем количество заключенных, которые нашли свои номера
}

set.seed(123) # чтобы была воспроизводимость
library(compiler)
cmp_se = cmpfun(single_experiment)

system.time({
    results =replicate(100000,cmp_se(100,50)) 
})
mean(results==100) # доля успешных экспериментов 

system.time({
    giper_results =replicate(100, mean(replicate(500,cmp_se(100,50))==100)) 
    })    
summary(giper_results)
quantile(giper_results, c(0.025,0.975))
plot(density(giper_results))

# для 100 раз по 10000
#      2.5%     97.5% 
# 0.3031800 0.3215675
```

### 2015-04-10 Упаковка функций в матрицу и использование их как объектов

По мотивам вопроса - http://vk.com/rstatistics?w=wall-8142131_2396%2Fall

Вообщем, с квазиобъектами у меня фейл тут получился...
#```{r}

object_producer = function(init = NULL){
    local({
        function(..., set = NULL) {
            if (!is.null(set) && !is.null(names(set))){
                for (each in names(set)){
                    assign(each, set[[each]], pos = 0)
                    }
                return(invisible(NULL))
                }
            gets = list(...)
            if (length(gets)>0){
                res = lapply(gets, function(each) {
                    if (!exists(each, where = 0)) stop("Field ",each, " not found")
                    get(x = each, pos = 0)
                    })
                return(res)
                }
            invisible(NULL)
            }  
        })
    }
one = object_producer()
two = object_producer()

one(set = list(a=2))
one("a")

two("a")

three = object_producer()
three("a")
#```

### 2015-04-21 Задача про двух мудрецов и 100 чисел.

http://habrahabr.ru/post/256293/
У некоторого султана было два мудреца: Али-ибн-Вали и Вали-ибн-Али. Желая убедиться в их мудрости, султан призвал мудрецов к себе и сказал: «Я задумал два числа. Оба они целые, каждое больше единицы, но меньше ста. Я перемножил эти числа и результат сообщу Али и при этом Вали я скажу сумму этих чисел. Если вы и вправду так мудры, как о вас говорят, то сможете узнать исходные числа».
Мудрецы задумались. Первым нарушил молчание Али.
— Я не знаю этих чисел, — сказал он, опуская голову.
— Я это знал, — подал голос Вали.
— Тогда я знаю эти числа, — обрадовался Али.
— Тогда и я знаю! — воскликнул Вали.
И мудрецы сообщили пораженному царю задуманные им числа.
Назовите эти числа.

2015-04-26 так я её и не доделал:()

```{r}

library(dplyr)
'append<-' = function(x,value) c(x,list(value))
res = list()
for(i in 2:99) for (j in i:99) if (i!=j) append(res) = c(first = i,second = j)

numbers = as.data.frame(do.call(rbind,res))
numbers = within(numbers, {prod = first*second
                           sum = first+second})

numbers = within(numbers, {dub_prod = duplicated(prod) | duplicated(prod, fromLast = TRUE) 
                           dub_sum = duplicated(sum) | duplicated(sum, fromLast = TRUE)
                           })

numbers   %>% filter(dub_prod)  %>% filter(dub_sum)  %>% invisible


```


### 2015-05-26 Реализция гребневой регрессии с помощью фиктивных кейсов.

Взято отсюду - https://stats.stackexchange.com/questions/151304/why-is-ridge-regression-called-ridge-why-is-it-needed-and-what-happens-when/151351#151351

Хочу проверить, совпадают ли результаты.


```{r}

library(MASS)
data(longley)
lambda = 0.01

names(longley)[1] <- "y"
lm.ridge(y ~ ., data = longley, lambda = lambda)

#                         GNP    Unemployed  Armed.Forces    Population          Year      Employed 
# -9.045258e+02  1.515219e-01  1.617130e-02  6.491346e-03 -1.159076e+00  5.519367e-01 -3.139751e-02 

str(longley)

dummy_cases = cbind(0,diag(sqrt(lambda),ncol(longley)-1))

colnames(dummy_cases) = colnames(longley)
new_dat = rbind(longley,dummy_cases)

lm(y ~ . , data = new_dat)



# в лоб не получилось, наверное, надо стандратизировать

sc_new_dat = as.data.frame(rbind(scale(longley),dummy_cases))

cf = coef(lm(y ~ . , data = sc_new_dat))

sc_y = sd(longley$y)
sc_x = apply(longley[,-1],2,sd)

cf[-1]/sc_x*sc_y

#         GNP   Unemployed Armed.Forces   Population         Year     Employed 
#  0.148388952  0.015899148  0.006575573 -1.134680575  0.576636967 -0.020149374

# похоже, но чуть-чуть отличается. Я посмотрел исходники - стандартное отклонение там по-другому считается - lдля генеральной совокупности. А зависимая переменная вообще не масштабируется.

yn = c(longley$y - mean(longley$y),rep(0,ncol(longley)-1))
sc_new_dat = as.data.frame(rbind(
    scale(longley[,-1])*sqrt((nrow(longley)-1)/nrow(longley)),
    dummy_cases[,-1]))

cf = coef(lm(yn ~ . , data = sc_new_dat))
sc_x = apply(longley[,-1],2,sd) * sqrt((nrow(longley)-1)/nrow(longley))
cf[-1]/sc_x
#         GNP   Unemployed Armed.Forces   Population         Year     Employed 
#  0.151621630  0.016239558  0.006531201 -1.158855755  0.546248012 -0.028284208 
# Более похоже, но чуть-чуть отличается все-равно.

```

Вердикт: метод можно использовать. В частности, с bigglm. Мне этого не хватало в avazu.

1. Стандартизируем X
2. Вычитаем центр из Y
3. Добавляем дополнительные кейсы с диагональным sqrt(lambda) и нулевым Y
4. Считаем модель
5. Делим коэффициенты на соответсвующее стандратное отклонение 

Непонятно, почему intercept не получается вычислить. И непонятно как быть с логистической регрессией - то есть какие значения в дополнительных кейсах для Y. Приходить только в голову, что добавлять двойной комплект кейсов - один с нулевым Y, другой с единичным.




